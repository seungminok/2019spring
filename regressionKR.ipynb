{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "중간고사 이후 \n",
    "## 함수를 구현하는 방법\n",
    "Y = ax+b 입력과 출력이 하나인 경우 이 함수를 확장 시켜서 입출력 값을 여러 개 만듦. \n",
    "\n",
    "Y=f(x) 함수의 기본 tool 입력한 값이 변형되어 출력 값이 나옴.\n",
    "\n",
    "x에는 어떤 식이든지 들어갈 수 있다는 게 중요함 ex. A1/x+b 또는 ax^2+b 이 경우에도 입력값과 출력값은 하나다.\n",
    "\n",
    "ax+b를 그림으로 그리는 게 중요하다. Y=a1x1+a2x2+a3x3+a4 라면 입력이 세 개, 출력이 한 개\n",
    "\n",
    "x =(a)> y x가 a만큼 곱해져서 y가 된다\n",
    "\n",
    "1=(b)> y 1이 b만큼 곱해져서 더한다. (y절편 때문에)\n",
    "\n",
    "출력이 여러 개일 경우, y1아래에 y2를 쌓는다. \n",
    "\n",
    "뉴럴네트워크 텐서플로우 dense라는 말은? X와 y의 관계 사이에 선을 빽빽하게 그어주는 것. \n",
    "\n",
    "Typical한 neural net은 fully connected = dense\n",
    "\n",
    "dense아닐 경우에, cnn 몰라도 됨.\n",
    "\n",
    "Fully connected 안된 건 그냥 a parameter 값이 0이라고 생각해도 됨.\n",
    "\n",
    "데이터가 있고, pair wise로 데이터가 수없이 존재할 때 가장 좋은 한 세트만 찾으면 된다. \n",
    "\n",
    "X와 y 사이에 또 다른 동그라미(node)를 그린다. 중간에 계산되어지는 값.\n",
    "\n",
    "구해지는 것은 x와 빈 동그라미 사이의 행렬 그리고 빈 동그라미와 y 의 행렬\n",
    "\n",
    "4x2 2x2 행렬이 구해짐. 숫자가 총 12개 \n",
    "\n",
    "Connection은 edge라고 함. 모든 그래프는 node와 edge로 이루어진다. \n",
    "\n",
    "X와 y는 layer라고 한다. 인접하지 않은 레이어들끼리는 edge가 있을 수 없다. \n",
    "\n",
    "edge에는 방향성이 들어간다. 방향성을 가진 node의 화살표는 weight, parameter라고 부름\n",
    "\n",
    "가중치가 너무 낮아서 선으로도 안그리는 거 weight가 0이다. 총 몇 개의 weight가 있는지 구할 수 있다. \n",
    "\n",
    "출력이라고 해도 되지만, 출력은 함수에서 계산되어 나온 계산값. Target은 정답값(데이터 속에 들어가있는 아웃풋 쪽에 들어가있는 페어 데이터) \n",
    "\n",
    "weight matrix가 남을 때, 이 네트워크가 예측할 것을 기대하면서 입력 값을 넣는다. 그럼 출력값이 나오는데, 데이터 속에 있는 target값과 일치하는 지 대조한다. 아웃풋과 타겟값은 위치는 똑같지만 목적이다르다. 데이터 속에서의 샘플을 뽑았을 때, 당연히 입력과 타겟값을 가지고 있다. 그 입력값을 넣어서 계산하면 출력값이 나온다. 그 출력값은 타겟값과는 차이가 있겠다. 훈련이 잘 될수록 타겟값과 일치도가 높다. 좋은 weight matrix가 구해져야 차이가 준다. 그 차이가 error\n",
    "\n",
    "에러가 적어야 predict를 잘하는 것. 좋은 데이터를 써야지 에러가 적다. 데이터가 많아야한다. (빅데이터) 그리고 훈련을 많이 시켜야한다. 그래프를 잘만들어야한다. \n",
    "\n",
    "Hidden layer가 중간에 들어가는 레이어 (입출력 사이에 숨어있다)\n",
    "\n",
    "Hidden layer와 node의 개수가 전체 함수의 complecity를 결정한다\n",
    "\n",
    "레이어의 개수가 많아지면 deep 하다고해서 딥러닝이 나옴\n",
    "\n",
    "Linear? X와 y의 관계가 linear? xy축으로 선으로 나타내지면 linear \n",
    "\n",
    "선형성에 비선형성을 부여하는 것 sigmoid 어떤 입력이 들어오더라도, 1,0사이로 축소시켜라\n",
    "\n",
    "지난시간까지는 숫자가 들어가서, 숫자로 예측되는 것. 지금부터는 입력은 숫잔데 출력은 숫자가 아니게 나온다. (음성인식-숫자가 들어왔는데 텍스트로 나온다) continuous한 값이 들어와도 출력을 예측해야하는 경우. Ex. 영화평점 입력값으로 많은 words들이 들어오더라도, good/bad만 결정하면 되는 것. Continuous 한 값을 categorical 하게 바꿔주는 것도 비선형성\n",
    "\n",
    "비선형성이 중요한 이유는 많은 기계학습들이 단순 숫자값->숫자값이 아니라 continuous 한 것을 인식해서 categorical 하게 바꾸는 것. 비선형성을 부여하지 않으면 잘 작동하지 않는다. \n",
    "\n",
    "많은 인공지능은 continuous한 값-> categorical 하게 패턴인식하는 과정.\n",
    "\n",
    "어떻게 비선형성을 부여하는가? Y=ax+b 에다가 sigmoid 를 붙여버림."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "data = pd.read_csv('regression.csv', delimiter = ',')\n",
    "X = data['X'].tolist()\n",
    "Y = data['Y'].tolist()\n",
    "x_train = np.asarray(X)\n",
    "y_train = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(1, input_shape=[1])    \n",
    "])\n",
    "optimizer = tf.keras.optimizers.RMSprop(0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='mse',\n",
    "              metrics=['mse']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 6ms/sample - loss: 62.4640 - mean_squared_error: 62.4640\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 69us/sample - loss: 58.7409 - mean_squared_error: 58.7409\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 110us/sample - loss: 56.1506 - mean_squared_error: 56.1506\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 111us/sample - loss: 54.0464 - mean_squared_error: 54.0464\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 184us/sample - loss: 52.2253 - mean_squared_error: 52.2253\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 125us/sample - loss: 50.5937 - mean_squared_error: 50.5937\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 141us/sample - loss: 49.0997 - mean_squared_error: 49.0997\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 149us/sample - loss: 47.7112 - mean_squared_error: 47.7112\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 222us/sample - loss: 46.4067 - mean_squared_error: 46.4067\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 140us/sample - loss: 45.1711 - mean_squared_error: 45.1711\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 124us/sample - loss: 43.9932 - mean_squared_error: 43.9932\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 139us/sample - loss: 42.8647 - mean_squared_error: 42.8647\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 104us/sample - loss: 41.7791 - mean_squared_error: 41.7791\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 185us/sample - loss: 40.7313 - mean_squared_error: 40.7313\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 117us/sample - loss: 39.7171 - mean_squared_error: 39.7171\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 114us/sample - loss: 38.7331 - mean_squared_error: 38.7331\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 147us/sample - loss: 37.7766 - mean_squared_error: 37.7766\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 120us/sample - loss: 36.8452 - mean_squared_error: 36.8452\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 109us/sample - loss: 35.9369 - mean_squared_error: 35.9369\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 102us/sample - loss: 35.0502 - mean_squared_error: 35.0502\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 104us/sample - loss: 34.1836 - mean_squared_error: 34.1836\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 104us/sample - loss: 33.3359 - mean_squared_error: 33.3359\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 88us/sample - loss: 32.5059 - mean_squared_error: 32.5059\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 89us/sample - loss: 31.6929 - mean_squared_error: 31.6929\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 159us/sample - loss: 30.8960 - mean_squared_error: 30.8960\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 131us/sample - loss: 30.1146 - mean_squared_error: 30.1146\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 129us/sample - loss: 29.3479 - mean_squared_error: 29.3479\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 117us/sample - loss: 28.5955 - mean_squared_error: 28.5955\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 118us/sample - loss: 27.8569 - mean_squared_error: 27.8569\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 135us/sample - loss: 27.1317 - mean_squared_error: 27.1317\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 169us/sample - loss: 26.4195 - mean_squared_error: 26.4195\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 124us/sample - loss: 25.7199 - mean_squared_error: 25.7199\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 179us/sample - loss: 25.0328 - mean_squared_error: 25.0328\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 112us/sample - loss: 24.3577 - mean_squared_error: 24.3577\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 108us/sample - loss: 23.6944 - mean_squared_error: 23.6944\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 127us/sample - loss: 23.0428 - mean_squared_error: 23.0428\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 123us/sample - loss: 22.4027 - mean_squared_error: 22.4027\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 97us/sample - loss: 21.7738 - mean_squared_error: 21.7738\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 157us/sample - loss: 21.1561 - mean_squared_error: 21.1561\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 90us/sample - loss: 20.5493 - mean_squared_error: 20.5493\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 74us/sample - loss: 19.9533 - mean_squared_error: 19.9533\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 136us/sample - loss: 19.3680 - mean_squared_error: 19.3680\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 67us/sample - loss: 18.7934 - mean_squared_error: 18.7934\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 64us/sample - loss: 18.2292 - mean_squared_error: 18.2292\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 189us/sample - loss: 17.6755 - mean_squared_error: 17.6755\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 113us/sample - loss: 17.1320 - mean_squared_error: 17.1320\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 158us/sample - loss: 16.5988 - mean_squared_error: 16.5988\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 120us/sample - loss: 16.0757 - mean_squared_error: 16.0757\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 119us/sample - loss: 15.5627 - mean_squared_error: 15.5627\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 159us/sample - loss: 15.0597 - mean_squared_error: 15.0597\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 83us/sample - loss: 14.5666 - mean_squared_error: 14.5666\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 92us/sample - loss: 14.0834 - mean_squared_error: 14.0834\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 147us/sample - loss: 13.6100 - mean_squared_error: 13.6100\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 140us/sample - loss: 13.1464 - mean_squared_error: 13.1464\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 114us/sample - loss: 12.6925 - mean_squared_error: 12.6925\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 155us/sample - loss: 12.2482 - mean_squared_error: 12.2482\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 96us/sample - loss: 11.8136 - mean_squared_error: 11.8136\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 137us/sample - loss: 11.3884 - mean_squared_error: 11.3884\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 94us/sample - loss: 10.9728 - mean_squared_error: 10.9728\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 191us/sample - loss: 10.5666 - mean_squared_error: 10.5666\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 104us/sample - loss: 10.1698 - mean_squared_error: 10.1698\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 141us/sample - loss: 9.7823 - mean_squared_error: 9.7823\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 91us/sample - loss: 9.4041 - mean_squared_error: 9.4041\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 121us/sample - loss: 9.0351 - mean_squared_error: 9.0351\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 103us/sample - loss: 8.6753 - mean_squared_error: 8.6753\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 106us/sample - loss: 8.3246 - mean_squared_error: 8.3246\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 165us/sample - loss: 7.9830 - mean_squared_error: 7.9830\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 150us/sample - loss: 7.6504 - mean_squared_error: 7.6504\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 101us/sample - loss: 7.3268 - mean_squared_error: 7.3268\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 115us/sample - loss: 7.0121 - mean_squared_error: 7.0121\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 98us/sample - loss: 6.7063 - mean_squared_error: 6.7063\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 100us/sample - loss: 6.4092 - mean_squared_error: 6.4092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 200us/sample - loss: 6.1208 - mean_squared_error: 6.1208\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 81us/sample - loss: 5.8412 - mean_squared_error: 5.8412\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 145us/sample - loss: 5.5701 - mean_squared_error: 5.5701\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 105us/sample - loss: 5.3075 - mean_squared_error: 5.3075\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 145us/sample - loss: 5.0534 - mean_squared_error: 5.0534\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 165us/sample - loss: 4.8078 - mean_squared_error: 4.8078\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 92us/sample - loss: 4.5704 - mean_squared_error: 4.5704\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 94us/sample - loss: 4.3413 - mean_squared_error: 4.3413\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 118us/sample - loss: 4.1203 - mean_squared_error: 4.1203\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 131us/sample - loss: 3.9075 - mean_squared_error: 3.9075\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 100us/sample - loss: 3.7026 - mean_squared_error: 3.7026\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 230us/sample - loss: 3.5057 - mean_squared_error: 3.5057\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 143us/sample - loss: 3.3166 - mean_squared_error: 3.3166\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 196us/sample - loss: 3.1352 - mean_squared_error: 3.1352\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 203us/sample - loss: 2.9615 - mean_squared_error: 2.9615\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 234us/sample - loss: 2.7953 - mean_squared_error: 2.7953\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 89us/sample - loss: 2.6365 - mean_squared_error: 2.6365\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 131us/sample - loss: 2.4851 - mean_squared_error: 2.4851\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 158us/sample - loss: 2.3408 - mean_squared_error: 2.3408\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 140us/sample - loss: 2.2036 - mean_squared_error: 2.2036\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 129us/sample - loss: 2.0735 - mean_squared_error: 2.0735\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 77us/sample - loss: 1.9501 - mean_squared_error: 1.9501\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 253us/sample - loss: 1.8334 - mean_squared_error: 1.8334\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 126us/sample - loss: 1.7233 - mean_squared_error: 1.7233\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 146us/sample - loss: 1.6197 - mean_squared_error: 1.6197\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 126us/sample - loss: 1.5223 - mean_squared_error: 1.5223\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 178us/sample - loss: 1.4310 - mean_squared_error: 1.4310\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 79us/sample - loss: 1.3456 - mean_squared_error: 1.3456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xb32799b00>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(2,11,1)\n",
    "y = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb32ae7630>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x,y, 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
